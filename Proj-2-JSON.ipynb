{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate skills dictionay that contains each skill and variations of its name\n",
    "#have an issue with R since the letter will mostly in the job description\n",
    "#does capitalization matter?\n",
    "skills = {\n",
    "    'Excel' : ['Excel','MSExcel'],\n",
    "    'SQL' : ['mysql', 'MS SQL', 'SQL', 'noSQL', 'NoSQL', 'NOSQL'],\n",
    "    'Python': ['python','Python'],\n",
    "    'JavaScript':['JS','JavaScript','javascript'],\n",
    "    'pandas': ['Pandas','pandas'],\n",
    "    'Hadoop': ['Hadoop'],\n",
    "    'MongoDB': ['Mongo','MongoDB'],\n",
    "    'Spark': ['Spark'],\n",
    "    'Leaflet':['Leafelet','leaflet'],\n",
    "    'Numpy':['numpy','Numpy'],\n",
    "    'VBA':['vba','VBA'],\n",
    "    'd3':['d3','D3'],\n",
    "    'Tableau':['Tableau','tableau'],\n",
    "    'R': ['RStudio'],\n",
    "    'Machine Learning':['Machine Learning','Machine learning','machine learning', 'Tensorflow']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from config import gkey\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion for browser\n",
    "def init_browser(): \n",
    "    executable_path = {'executable_path':'./chromedriver'}\n",
    "    return Browser('chrome',**executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an instance of a broswer\n",
    "\n",
    "indeed_url = \"https://www.indeed.com/jobs?as_and=data+science&as_phr=&as_any=&as_not=&as_ttl=data+scientist&as_cmp=&jt=all&st=&as_src=&salary=&radius=0&l=CA&fromage=any&limit=50&sort=&psf=advsrch\"\n",
    "#url for data analyst (entry)\n",
    "#url = \"https://www.indeed.com/jobs?as_and=data+analyst&as_phr=&as_any=&as_not=&as_ttl=data+analyst&as_cmp=&jt=all&st=&as_src=&salary=&radius=5&l=CA&fromage=any&limit=50&sort=date&psf=advsrch\"\n",
    "\n",
    "#url = \"https://www.indeed.com/jobs?q=(Python+or+SQL+or+MySQL+or+Tableau+or+VBA+or+Excel+or+Pandas+or+Javascript+or+D3+or+Splinter+or+JSON+or+Machine+or+Learning+or+Leaflet+or+GeoJson)+-machinist,+-CNC,&l=CA&radius=0&jt=fulltime&explvl=mid_level&sort=date&limit=50&st=employer&fromage=3\"\n",
    "#url = \"https://www.indeed.com/jobs?q=data+analyst+(Python+or+SQL+or+MySQL+or+Tableau+or+VBA+or+Excel+or+Pandas+or+Javascript+or+D3+or+web-scraping+or+JSON+or+Machine+or+Learning+or+Leaflet+or+GeoJson)+-machinist,+-CNC,&l=CA&radius=0&jt=fulltime&explvl=mid_level&sort=date&limit=50&st=employer&fromage=3\"\n",
    "browser = init_browser()\n",
    "browser.driver.set_window_size(1680, 1050)\n",
    "browser.visit(indeed_url)\n",
    "html= browser.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat soup object\n",
    "soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Find all divs which contain a job posting\n",
    "#find the link of each job posting save them to a list. instead of registering the full link, only store\n",
    "#the first 50 characters (that should be enough to create uniqueness between postings)\n",
    "div_results = soup.find_all('div', {'class':'row result clickcard'})\n",
    "a_tags = []\n",
    "\n",
    "div_results\n",
    "for div in div_results:\n",
    "    a = div.a.get('href')\n",
    "    a_tags.append(a[:50])\n",
    "    #print(a[:50])\n",
    "    #print(\"------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/pagead/clk?mo=r&ad=-6NYlbfkN0CFSg06BLvPbR-HAeeUdX',\n",
       " '/pagead/clk?mo=r&ad=-6NYlbfkN0BZGVbs71v5EJ1Sm8QuTI',\n",
       " '/pagead/clk?mo=r&ad=-6NYlbfkN0Bw1nCGA-im3c4lgntbkP',\n",
       " '/pagead/clk?mo=r&ad=-6NYlbfkN0CFSg06BLvPbR-HAeeUdX',\n",
       " '/pagead/clk?mo=r&ad=-6NYlbfkN0AR_qGNZB4jkM1DWpdIph',\n",
       " '/pagead/clk?mo=r&ad=-6NYlbfkN0Bw1nCGA-im3c4lgntbkP',\n",
       " '/pagead/clk?mo=r&ad=-6NYlbfkN0CleyozbRSfLCtZHtSeSH',\n",
       " '/company/Bridgepoint-Education/jobs/Junior-Data-Sc',\n",
       " '/rc/clk?jk=5c99379f444efe0c&fccid=c1099851e9794854',\n",
       " '/rc/clk?jk=56e9ad66b5f392da&fccid=ddae355770caf5ef',\n",
       " '/company/M-Theory-Solutions/jobs/Data-Scientist-44',\n",
       " '/rc/clk?jk=273ff3a4c6fde5b6&fccid=8b219f1987ef65ea',\n",
       " '/rc/clk?jk=7f1f5a6292581fc7&fccid=68ec8a8ee6cf5ac6',\n",
       " '/rc/clk?jk=4084e8caad382bd3&fccid=128451ec69a4c285',\n",
       " '/company/Lumen-Solutions-Inc/jobs/Data-Scientist-C',\n",
       " '/rc/clk?jk=31a1a5e5ac57629c&fccid=16d24b4316c5d97f',\n",
       " '/rc/clk?jk=1bfbefe559bc942f&fccid=2431bcc75b874651',\n",
       " '/rc/clk?jk=944268a7d74bafba&fccid=fbd294446d1ea4d4',\n",
       " '/rc/clk?jk=2a029814b087cb71&fccid=0bed8e17bc113980',\n",
       " '/rc/clk?jk=89a2512e4b0c450c&fccid=8c49e99f20f89e48',\n",
       " '/rc/clk?jk=9f8169bd8e151d51&fccid=8e9ae7de18dcd13e',\n",
       " '/rc/clk?jk=9fa6106b930d816e&fccid=822bc5d9a49270ea',\n",
       " '/rc/clk?jk=fd6219ac4a3a9dab&fccid=16d24b4316c5d97f',\n",
       " '/rc/clk?jk=a66436f2fa65ef76&fccid=237908de095b6446',\n",
       " '/rc/clk?jk=d2e6422ab0fce025&fccid=7136762d065a5ad7',\n",
       " '/company/Paradigm-Infotech,-Inc/jobs/Data-Scientis',\n",
       " '/rc/clk?jk=f77df572eeddffd7&fccid=4e041af1d0af1bc8',\n",
       " '/rc/clk?jk=84b809e8dae79823&fccid=7a3824693ee1074b',\n",
       " '/rc/clk?jk=5ce7de375db868a4&fccid=1c70eede37c5caee',\n",
       " '/rc/clk?jk=0adb849f49309063&fccid=1f420427b06ff1e7',\n",
       " '/rc/clk?jk=1915a0676efd9fd8&fccid=1dd77792e14d7992',\n",
       " '/rc/clk?jk=9b55ad05065d09f6&fccid=f89deb5a97c7738a',\n",
       " '/company/Serial-Metrics/jobs/Remote-Data-Scientist',\n",
       " '/company/M-Theory-Solutions/jobs/Data-Scientist-5d',\n",
       " '/rc/clk?jk=5c84cfeaa0660b3b&fccid=86e9be6ce380173e',\n",
       " '/rc/clk?jk=819f62786da66c65&fccid=09abad886b83c501',\n",
       " '/company/FlowCommand-Inc./jobs/Data-Scientist-4575',\n",
       " '/rc/clk?jk=636918e658eec5c5&fccid=d3ee4a7355a0fb60',\n",
       " '/company/LeoLabs,-Inc./jobs/Data-Scientist-94ceca8',\n",
       " '/rc/clk?jk=264b4ce61ad3b658&fccid=b70e59520ec08775',\n",
       " '/rc/clk?jk=95d9a941220172a1&fccid=fe2d21eef233e94a',\n",
       " '/rc/clk?jk=da3a39b22090e616&fccid=3dca573557f8fb68',\n",
       " '/company/BitMart/jobs/Data-Scientist-efb070c9897ab',\n",
       " '/rc/clk?jk=1cc2c0eeafcb455a&fccid=8b219f1987ef65ea',\n",
       " '/rc/clk?jk=7bb7af219a11bc21&fccid=bfdada4457994fb4',\n",
       " '/company/Deus-Ex-Machina/jobs/Data-Scientist-14602',\n",
       " '/company/Astral-Knowlegde-Services/jobs/Data-Scien',\n",
       " '/rc/clk?jk=006e29d3a1939dc3&fccid=0674a2825e6492f5',\n",
       " '/rc/clk?jk=967716f141a824cd&fccid=53242361973750f7',\n",
       " '/rc/clk?jk=e09959e7058561a8&fccid=dfc44f3b8c44a6db',\n",
       " '/rc/clk?jk=11991f04e76b4ba0&fccid=c1099851e9794854',\n",
       " '/rc/clk?jk=37b27ef78d95f422&fccid=5bcd1ef0a7f4fb99',\n",
       " '/rc/clk?jk=5b30c362a00c670c&fccid=1c70eede37c5caee',\n",
       " '/rc/clk?jk=3d44b2c5f187a769&fccid=c734dc8b03fc4451',\n",
       " '/rc/clk?jk=7bab7ef407f77261&fccid=92dad6c269775a38',\n",
       " '/rc/clk?jk=6395ef3f1876ce07&fccid=86d4b5da3ae0fbfe']"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print length of tags list\n",
    "page_tag_count = len(a_tags) \n",
    "print(page_tag_count)\n",
    "#print(a_tags)\n",
    "a_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "error at  41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "\n",
    "counter = 0\n",
    "\n",
    "# Initialize empty dictionarys and lists to dump into JSON objects\n",
    "x = {}\n",
    "indeed_job_data = []\n",
    "locations = []\n",
    "skills_count = {}\n",
    "target_city = []\n",
    "skills_list = []\n",
    "\n",
    "\n",
    "# Loop through a_tag content and click on job postings\n",
    "for tag in a_tags:\n",
    "    browser.find_link_by_partial_href(tag).click()\n",
    "    time.sleep(1)\n",
    "    html2 = browser.html\n",
    "    soup2 = bs(html2, \"html.parser\")\n",
    "    \n",
    "    try:\n",
    "        job_desc = soup2.find('div', {'id':'vjs-tab-job'}).get_text()\n",
    "        company = soup2.find('span', {'id':'vjs-cn'}).get_text()\n",
    "        title = soup2.find('div', {'id':'vjs-jobtitle'}).get_text()\n",
    "        location = soup2.find('span', {'id':'vjs-loc'}).get_text().split(\" - \")[1].split(\",\")[0]\n",
    "        for skill, terms in skills.items():\n",
    "            for term in terms:\n",
    "                if term in job_desc:\n",
    "                        skills_list.append(term)\n",
    "                break\n",
    "        \n",
    "        target_city = location\n",
    "        target_url = \"https://maps.googleapis.com/maps/api/geocode/json?\" \\\n",
    "    \"address=%s&key=%s\" % (target_city, gkey)\n",
    "        req = requests.get(target_url)\n",
    "        res = req.json()\n",
    "        result = res['results'][0]\n",
    "\n",
    "        \n",
    "        geodata = []\n",
    "        lat = result['geometry']['location']['lat']\n",
    "        long = result['geometry']['location']['lng']\n",
    "        \n",
    "        x = { \n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\n",
    "                \"type\": \"Point\",\n",
    "                \"coordinates\": [lat, long]\n",
    "            },\n",
    "            \"properties\": {\n",
    "            \"website\" : 'Indeed',\n",
    "            \"job title\" : title,\n",
    "            \"job_posting_url\" : indeed_url,\n",
    "            \"job_scrape_date\": \"10/25/18\",\n",
    "            \"job_posting_date\": \"2 days ago\",\n",
    "            'company': company,\n",
    "            'skills' : skills_list,\n",
    "            'city' : location\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        indeed_job_data.append(x) \n",
    "\n",
    "    except AttributeError as ex:\n",
    "        print(ex)\n",
    "        print('error at ', counter)\n",
    "        \n",
    "    counter += 1\n",
    "    location = []\n",
    "    skills_list = []\n",
    "    x = {}\n",
    "    data = {}\n",
    "\n",
    "    print(counter)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Excel', 'Hadoop', 'Machine Learning']"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeed_job_data[5]['properties']['skills']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Excel': 17,\n",
       " 'SQL': 0,\n",
       " 'Python': 2,\n",
       " 'JavaScript': 2,\n",
       " 'pandas': 3,\n",
       " 'Hadoop': 14,\n",
       " 'MongoDB': 1,\n",
       " 'Spark': 8,\n",
       " 'Leaflet': 0,\n",
       " 'Numpy': 1,\n",
       " 'VBA': 0,\n",
       " 'd3': 1,\n",
       " 'Tableau': 13,\n",
       " 'R': 0,\n",
       " 'Machine Learning': 17}"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeed_skills_count = {}\n",
    "for skill, terms in skills.items():\n",
    "    indeed_skills_count[skill]=0\n",
    "\n",
    "count = 0\n",
    "\n",
    "for entry in indeed_job_data:\n",
    "    for skill, terms in skills.items():\n",
    "        for term in terms:\n",
    "            if term in entry['properties']['skills']:\n",
    "\n",
    "                indeed_skills_count[skill] +=1\n",
    "                count +=1\n",
    "\n",
    "                break\n",
    "indeed_skills_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"https://www.monster.com/jobs/search/?q=data-scientist&where=CA&intcid=skr_navigation_nhpso_searchMain&jobid=201469712\"\n",
    "monster_url = \"https://www.monster.com/jobs/search/Full-Time_8?q=data-scientist&where=CA&tm=3&jobid=202164956\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = init_browser()\n",
    "browser.driver.set_window_size(1680, 1050)\n",
    "browser.visit(monster_url)\n",
    "html= browser.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://job-openings.monster.com/data-scientist-san-jose-ca-us-collabe\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/senior-data-scientist-san-francisco-c\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/senior-data-scientist-san-francisco-c\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/data-scientist-san-diego-ca-us-ablefo\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/data-scientist-san-diego-ca-us-apex-s\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/data-architect-data-science-san-jose-\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/sr-manager-data-science-san-diego-ca-\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/associate-sales-consultant-stockton-c\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/senior-devops-engineer-santa-barbara-\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/senior-front-end-engineer-san-francis\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/watson-content-analytics-developer-fr\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/research-associate-san-diego-ca-us-ra\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/watson-content-analytics-developer-fr\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/computer-it-multiple-positions-san-fr\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/database-engineer-3-mountain-view-ca-\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/front-end-ui-software-engineer-sunnyv\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/senior-experienced-teradata-developer\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/senior-developer-santa-clara-ca-us-hi\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/research-associate-microbial-discover\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/data-scientist-python-sql-tableau-oak\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/data-scientist-san-diego-ca-us-apex-s\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/hospital-sales-account-executive-tya2\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/software-developer-santa-barbara-ca-u\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/microbial-discovery-research-associat\n",
      "------------------------------------------------------------------------------------------\n",
      "https://job-openings.monster.com/data-scientist-must-answer-questions-\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Find all divs which contain a job posting\n",
    "#find the link of each job posting save them to a list. instead of registering the full link, only store\n",
    "#the first 50 characters (that should be enough to create uniqueness between postings)\n",
    "soup = bs(html, \"html.parser\")\n",
    "div_results = soup.find_all('div', {'class':'summary'})\n",
    "\n",
    "a_tags = []\n",
    "\n",
    "div_results\n",
    "for div in div_results:\n",
    "    a = div.a.get('href')\n",
    "    a_tags.append(a[:70])\n",
    "    print(a[:70])\n",
    "    print(\"------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://job-openings.monster.com/data-scientist-san-jose-ca-us-collabe',\n",
       " 'https://job-openings.monster.com/senior-data-scientist-san-francisco-c',\n",
       " 'https://job-openings.monster.com/senior-data-scientist-san-francisco-c',\n",
       " 'https://job-openings.monster.com/data-scientist-san-diego-ca-us-ablefo',\n",
       " 'https://job-openings.monster.com/data-scientist-san-diego-ca-us-apex-s',\n",
       " 'https://job-openings.monster.com/data-architect-data-science-san-jose-',\n",
       " 'https://job-openings.monster.com/sr-manager-data-science-san-diego-ca-',\n",
       " 'https://job-openings.monster.com/associate-sales-consultant-stockton-c',\n",
       " 'https://job-openings.monster.com/senior-devops-engineer-santa-barbara-',\n",
       " 'https://job-openings.monster.com/senior-front-end-engineer-san-francis',\n",
       " 'https://job-openings.monster.com/watson-content-analytics-developer-fr',\n",
       " 'https://job-openings.monster.com/research-associate-san-diego-ca-us-ra',\n",
       " 'https://job-openings.monster.com/watson-content-analytics-developer-fr',\n",
       " 'https://job-openings.monster.com/computer-it-multiple-positions-san-fr',\n",
       " 'https://job-openings.monster.com/database-engineer-3-mountain-view-ca-',\n",
       " 'https://job-openings.monster.com/front-end-ui-software-engineer-sunnyv',\n",
       " 'https://job-openings.monster.com/senior-experienced-teradata-developer',\n",
       " 'https://job-openings.monster.com/senior-developer-santa-clara-ca-us-hi',\n",
       " 'https://job-openings.monster.com/research-associate-microbial-discover',\n",
       " 'https://job-openings.monster.com/data-scientist-python-sql-tableau-oak',\n",
       " 'https://job-openings.monster.com/data-scientist-san-diego-ca-us-apex-s',\n",
       " 'https://job-openings.monster.com/hospital-sales-account-executive-tya2',\n",
       " 'https://job-openings.monster.com/software-developer-santa-barbara-ca-u',\n",
       " 'https://job-openings.monster.com/microbial-discovery-research-associat',\n",
       " 'https://job-openings.monster.com/data-scientist-must-answer-questions-']"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print length of tags list\n",
    "page_tag_count = len(a_tags) \n",
    "print(page_tag_count)\n",
    "#print(a_tags)\n",
    "a_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "error at  8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "counter = 0\n",
    "\n",
    "# Initialize empty dictionarys and lists to dump into JSON objects\n",
    "x = {}\n",
    "monster_job_data = []\n",
    "locations = []\n",
    "skills_count = {}\n",
    "target_city = []\n",
    "skills_list = []\n",
    "\n",
    "\n",
    "# Loop through a_tag content and click on job postings\n",
    "for tag in a_tags:\n",
    "    browser.find_link_by_partial_href(tag).click()\n",
    "    time.sleep(1)\n",
    "    html2 = browser.html\n",
    "    soup2 = bs(html2, \"html.parser\")\n",
    "\n",
    "    \n",
    "    try:\n",
    "        # set variables to dump into JSON \n",
    "        location = soup2.find('h2', {'class':'subtitle'}).get_text().split(\",\")[0].split(\",\")[0]\n",
    "        job_desc = soup2.find('div', {'class':'details-content'}).get_text()\n",
    "        title = soup2.find('h1', {'class':'title'}).get_text().strip()\n",
    "\n",
    "\n",
    "        \n",
    "        for skill, terms in skills.items():\n",
    "            for term in terms:\n",
    "                if term in job_desc:\n",
    "                        skills_list.append(term)\n",
    "                break\n",
    "        \n",
    "        target_city = location\n",
    "        target_url = \"https://maps.googleapis.com/maps/api/geocode/json?\" \\\n",
    "    \"address=%s&key=%s\" % (target_city, gkey)\n",
    "        req = requests.get(target_url)\n",
    "        res = req.json()\n",
    "        result = res['results'][0]\n",
    "\n",
    "        lat = result['geometry']['location']['lat']\n",
    "        long = result['geometry']['location']['lng']\n",
    "        \n",
    "        x = { \n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\n",
    "                \"type\": \"Point\",\n",
    "                \"coordinates\": [lat, long]\n",
    "            },\n",
    "            \"properties\": {\n",
    "            \"website\" : 'Monster',\n",
    "            \"job title\" : title,\n",
    "            \"job_posting_url\" : monster_url,\n",
    "            \"job_scrape_date\": \"10/25/18\",\n",
    "            \"job_posting_date\": \"2 days ago\",\n",
    "            'company': \"NA\",\n",
    "            'skills' : skills_list,\n",
    "            'city' : location\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        monster_job_data.append(x) \n",
    "\n",
    "    except AttributeError as ex:\n",
    "        print(ex)\n",
    "        print('error at ', counter)\n",
    "        \n",
    "    counter += 1\n",
    "    location = []\n",
    "    skills_list = []\n",
    "    x = {}\n",
    "    data = {}\n",
    "\n",
    "    print(counter)\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Feature',\n",
       " 'geometry': {'type': 'Point', 'coordinates': [37.7749295, -122.4194155]},\n",
       " 'properties': {'website': 'Monster',\n",
       "  'job title': 'Senior Data Scientist at Clandica Inc',\n",
       "  'job_posting_url': 'https://www.monster.com/jobs/search/Full-Time_8?q=data-scientist&where=CA&tm=3&jobid=202164956',\n",
       "  'job_scrape_date': '10/25/18',\n",
       "  'job_posting_date': '2 days ago',\n",
       "  'company': 'NA',\n",
       "  'skills': ['python'],\n",
       "  'city': 'San Francisco'}}"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monster_job_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Excel': 6,\n",
       " 'SQL': 0,\n",
       " 'Python': 2,\n",
       " 'JavaScript': 3,\n",
       " 'pandas': 1,\n",
       " 'Hadoop': 7,\n",
       " 'MongoDB': 0,\n",
       " 'Spark': 2,\n",
       " 'Leaflet': 0,\n",
       " 'Numpy': 0,\n",
       " 'VBA': 0,\n",
       " 'd3': 0,\n",
       " 'Tableau': 5,\n",
       " 'R': 0,\n",
       " 'Machine Learning': 0}"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monster_skills_count = {}\n",
    "for skill, terms in skills.items():\n",
    "    monster_skills_count[skill]=0\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "for entry in monster_job_data:\n",
    "    for skill, terms in skills.items():\n",
    "        for term in terms:\n",
    "            if term in entry['properties']['skills']:\n",
    "\n",
    "                monster_skills_count[skill] +=1\n",
    "                count +=1\n",
    "\n",
    "                break\n",
    "monster_skills_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this code will advance the scraping to the next jobs page and close pop-up\n",
    "browser.click_link_by_partial_text('Next')\n",
    "browser.click_link_by_id('popover-close-link')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedin_url = \"https://www.linkedin.com/jobs/search/?distance=25&f_E=2%2C3&f_GC=us.7-1-0-38-1%2Cus.7-1-0-37-41%2Cus.7-1-0-19-57%2Cus.7-1-0-43-16%2Cus.7-1-0-34-21%2Cus.7-1-0-30-18&f_T=25190&f_TP=1%2C2&keywords=data%20scientist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = init_browser()\n",
    "browser.driver.set_window_size(1680, 1050)\n",
    "browser.visit(linkedin_url)\n",
    "html= browser.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.linkedin.com/jobs/view/data-scientist-management-consultan\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/data-scientist-product-analytics-at\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/data-scientist-at-zumper-930975483?\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/data-scientist-at-envoy-930973938?t\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/data-scientist-growth-at-smartnews-\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/data-scientist-at-square-up-media-9\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/data-scientist-at-directly-92432803\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/data-scientist-at-grand-rounds-inc-\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/data-scientist-at-spin-electric-sco\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/data-scientist-at-nutanix-930528785\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/data-scientist-at-goat-sneaker-mark\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/data-scientist-at-vevo-917574663?tr\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/senior-data-scientist-at-pocket-gem\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/senior-data-scientist-at-coinbase-9\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/data-scientist-at-motive-929606084?\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/data-scientist-at-optimizely-868897\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/data-scientist-at-jobs-%40-thejobne\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/data-scientist-at-central-business-\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/data-scientist-at-esurance-92908998\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/data-scientist-engineer-analytics-a\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/data-scientist-at-skillz-inc-929096\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/senior-data-scientist-at-clarivate-\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/senior-data-scientist-at-factual-in\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/senior-data-scientist-at-cybercoder\n",
      "------------------------------------------------------------------------------------------\n",
      "https://www.linkedin.com/jobs/view/sr-data-scientist-at-keeptruckin-92\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "soup = bs(html, \"html.parser\")\n",
    "div_results = soup.find_all('li', {'itemprop':'itemListElement'})\n",
    "\n",
    "a_tags = []\n",
    "\n",
    "div_results\n",
    "for div in div_results:\n",
    "    a = div.a.get('href')\n",
    "    a_tags.append(a[:70])\n",
    "    print(a[:70])\n",
    "    print(\"------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.linkedin.com/jobs/view/data-scientist-management-consultan',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-product-analytics-at',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-zumper-930975483?',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-envoy-930973938?t',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-growth-at-smartnews-',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-square-up-media-9',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-directly-92432803',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-grand-rounds-inc-',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-spin-electric-sco',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-nutanix-930528785',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-goat-sneaker-mark',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-vevo-917574663?tr',\n",
       " 'https://www.linkedin.com/jobs/view/senior-data-scientist-at-pocket-gem',\n",
       " 'https://www.linkedin.com/jobs/view/senior-data-scientist-at-coinbase-9',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-motive-929606084?',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-optimizely-868897',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-jobs-%40-thejobne',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-central-business-',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-esurance-92908998',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-engineer-analytics-a',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-skillz-inc-929096',\n",
       " 'https://www.linkedin.com/jobs/view/senior-data-scientist-at-clarivate-',\n",
       " 'https://www.linkedin.com/jobs/view/senior-data-scientist-at-factual-in',\n",
       " 'https://www.linkedin.com/jobs/view/senior-data-scientist-at-cybercoder',\n",
       " 'https://www.linkedin.com/jobs/view/sr-data-scientist-at-keeptruckin-92']"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print length of tags list\n",
    "page_tag_count = len(a_tags) \n",
    "print(page_tag_count)\n",
    "\n",
    "a_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "counter = 0\n",
    "\n",
    "# Initialize empty dictionarys and lists to dump into JSON objects\n",
    "x = {}\n",
    "linkedin_job_data = []\n",
    "locations = []\n",
    "skills_count = {}\n",
    "target_city = []\n",
    "skills_list = []\n",
    "\n",
    "# Loop through a_tag content and click on job postings\n",
    "for tag in a_tags:\n",
    "\n",
    "    browser.find_link_by_partial_href(tag).click()\n",
    "    time.sleep(1)\n",
    "    html2 = browser.html\n",
    "    soup2 = bs(html2, \"html.parser\")\n",
    "\n",
    "    try:\n",
    "        # set variables to dump into JSON \n",
    "        location = soup2.find('h3', {'class':'location'}).get_text().split(\",\")[0]\n",
    "        company = soup2.find('span', {'class':'company'}).get_text()\n",
    "        job_desc = soup2.find('div', {'class':'description-section'}).get_text()\n",
    "        title = soup2.find('h1', {'class':'title'}).get_text().strip()\n",
    "        \n",
    "        for skill, terms in skills.items():\n",
    "            for term in terms:\n",
    "                if term in job_desc:\n",
    "                        skills_list.append(term)\n",
    "                break\n",
    "        \n",
    "        target_city = location\n",
    "        target_url = \"https://maps.googleapis.com/maps/api/geocode/json?\" \\\n",
    "    \"address=%s&key=%s\" % (target_city, gkey)\n",
    "        req = requests.get(target_url)\n",
    "        res = req.json()\n",
    "        result = res['results'][0]\n",
    "\n",
    "        lat = result['geometry']['location']['lat']\n",
    "        long = result['geometry']['location']['lng']\n",
    "        \n",
    "        x = { \n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\n",
    "                \"type\": \"Point\",\n",
    "                \"coordinates\": [lat, long]\n",
    "            },\n",
    "            \"properties\": {\n",
    "            \"website\" : 'linkedin',\n",
    "            \"job title\" : title,\n",
    "            \"job_posting_url\" : linkedin_url,\n",
    "            \"job_scrape_date\": \"10/25/18\",\n",
    "            \"job_posting_date\": \"2 days ago\",\n",
    "            'company': \"NA\",\n",
    "            'skills' : skills_list,\n",
    "            'city' : location\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        linkedin_job_data.append(x) \n",
    "\n",
    "    except WebDriverException as ex:\n",
    "        print(ex)\n",
    "        print('error at ', counter)\n",
    "        \n",
    "    browser.back()\n",
    "    \n",
    "    counter += 1\n",
    "    location = []\n",
    "    skills_list = []\n",
    "    x = {}\n",
    "    data = {}\n",
    "\n",
    "    print(counter)\n",
    "   # print(job_data)  \n",
    "\n",
    "    #job_json.append(job_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Feature',\n",
       " 'geometry': {'type': 'Point', 'coordinates': [37.7749295, -122.4194155]},\n",
       " 'properties': {'website': 'linkedin',\n",
       "  'job title': 'Data Scientist, Product Analytics',\n",
       "  'job_posting_url': 'https://www.linkedin.com/jobs/search/?distance=25&f_E=2%2C3&f_GC=us.7-1-0-38-1%2Cus.7-1-0-37-41%2Cus.7-1-0-19-57%2Cus.7-1-0-43-16%2Cus.7-1-0-34-21%2Cus.7-1-0-30-18&f_T=25190&f_TP=1%2C2&keywords=data%20scientist',\n",
       "  'job_scrape_date': '10/25/18',\n",
       "  'job_posting_date': '2 days ago',\n",
       "  'company': 'NA',\n",
       "  'skills': ['Excel', 'Tableau'],\n",
       "  'city': 'San Francisco'}}"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkedin_job_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Excel': 9,\n",
       " 'SQL': 0,\n",
       " 'Python': 0,\n",
       " 'JavaScript': 1,\n",
       " 'pandas': 1,\n",
       " 'Hadoop': 4,\n",
       " 'MongoDB': 0,\n",
       " 'Spark': 8,\n",
       " 'Leaflet': 0,\n",
       " 'Numpy': 2,\n",
       " 'VBA': 0,\n",
       " 'd3': 1,\n",
       " 'Tableau': 4,\n",
       " 'R': 0,\n",
       " 'Machine Learning': 5}"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkedin_skills_count = {}\n",
    "for skill, terms in skills.items():\n",
    "    linkedin_skills_count[skill]=0\n",
    "\n",
    "count = 0\n",
    "\n",
    "for entry in linkedin_job_data:\n",
    "    for skill, terms in skills.items():\n",
    "        for term in terms:\n",
    "            if term in entry['properties']['skills']:\n",
    "\n",
    "                linkedin_skills_count[skill] +=1\n",
    "                count +=1\n",
    "\n",
    "                break\n",
    "linkedin_skills_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Feature',\n",
       " 'geometry': {'type': 'Point', 'coordinates': [37.7749295, -122.4194155]},\n",
       " 'properties': {'website': 'linkedin',\n",
       "  'job title': 'Data Scientist, Product Analytics',\n",
       "  'job_posting_url': 'https://www.linkedin.com/jobs/search/?distance=25&f_E=2%2C3&f_GC=us.7-1-0-38-1%2Cus.7-1-0-37-41%2Cus.7-1-0-19-57%2Cus.7-1-0-43-16%2Cus.7-1-0-34-21%2Cus.7-1-0-30-18&f_T=25190&f_TP=1%2C2&keywords=data%20scientist',\n",
       "  'job_scrape_date': '10/25/18',\n",
       "  'job_posting_date': '2 days ago',\n",
       "  'company': 'NA',\n",
       "  'skills': ['Excel', 'Tableau'],\n",
       "  'city': 'San Francisco'}}"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkedin_job_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
